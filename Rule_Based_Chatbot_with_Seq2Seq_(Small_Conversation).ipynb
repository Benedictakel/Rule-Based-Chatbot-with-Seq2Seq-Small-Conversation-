{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOstqEL02FGBz6gYMFZ6hvT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benedictakel/Rule-Based-Chatbot-with-Seq2Seq-Small-Conversation-/blob/main/Rule_Based_Chatbot_with_Seq2Seq_(Small_Conversation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UoQaeKwo3_Nl"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "yQJedy_s4TIA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_sentences = [\"hello\", \"how are you\", \"good morning\", \"thank you\"]\n",
        "fra_sentences = [\"bonjour\", \"comment Ã§a va\", \"bon matin\", \"merci\"]\n"
      ],
      "metadata": {
        "id": "gNzpsDhx4aCW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "tokenizer_fr = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "tokenizer_en.fit_on_texts(eng_sentences)\n",
        "tokenizer_fr.fit_on_texts(fra_sentences)\n",
        "\n",
        "seq_en = tokenizer_en.texts_to_sequences(eng_sentences)\n",
        "seq_fr = tokenizer_fr.texts_to_sequences(fra_sentences)\n",
        "\n",
        "max_en = max(len(s) for s in seq_en)\n",
        "max_fr = max(len(s) for s in seq_fr)\n",
        "\n",
        "seq_en = tf.keras.preprocessing.sequence.pad_sequences(seq_en, maxlen=max_en, padding='post')\n",
        "seq_fr = tf.keras.preprocessing.sequence.pad_sequences(seq_fr, maxlen=max_fr, padding='post')"
      ],
      "metadata": {
        "id": "xUAtm4Pq4g32"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim=32\n",
        "# Encoder\n",
        "enc_inputs = layers.Input(shape=(max_en,))\n",
        "enc_emb = layers.Embedding(len(tokenizer_en.word_index)+1, latent_dim)(enc_inputs)\n",
        "_, state_h, state_c = layers.LSTM(latent_dim, return_state=True)(enc_emb)\n",
        "enc_states = [state_h, state_c]\n",
        "# Decoder\n",
        "dec_inputs = layers.Input(shape=(max_fr,))\n",
        "dec_emb = layers.Embedding(len(tokenizer_fr.word_index)+1, latent_dim)(dec_inputs)\n",
        "dec_lstm = layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "dec_outputs, _, _ = dec_lstm(dec_emb, initial_state=enc_states)\n",
        "dec_dense = layers.Dense(len(tokenizer_fr.word_index)+1, activation='softmax')\n",
        "dec_outputs = dec_dense(dec_outputs)\n",
        "\n",
        "model = tf.keras.Model([enc_inputs, dec_inputs], dec_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "model.fit([seq_en, seq_fr], seq_fr.reshape(seq_fr.shape[0], -1, 1), epochs=500, verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7ugCawP4prv",
        "outputId": "1a18ee96-0724-420b-ab04-84fab86fd9a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79021a7a2290>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('seq2seq_small.keras')\n",
        "print(\"Saved seq2seq_small/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkEfc8es5VsW",
        "outputId": "076f1b6e-2aa3-47b4-c7d6-a25b11709651"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved seq2seq_small/\n"
          ]
        }
      ]
    }
  ]
}